[["day1-intro-fundamentals.html", "Chapter 9 Advanced Quantitative Text Analysis: Day 1: Introduction &amp; Fundamentals", " Chapter 9 Advanced Quantitative Text Analysis: Day 1: Introduction &amp; Fundamentals library(reticulate) use_virtualenv(&quot;~/python-r-env&quot;, required = TRUE) library(tensorflow) "],["day1-intro-fundamentals.html", "Chapter 10 Advanced Quantitative Text Analysis: Day 1: Introduction &amp; Fundamentals", " Chapter 10 Advanced Quantitative Text Analysis: Day 1: Introduction &amp; Fundamentals This chapter serves as an introduction to the field of quantitative text analysis, beginning with fundamental concepts and traditional methods, then transitioning to the powerful capabilities of deep learning for textual data. We will explore the motivations for using computational methods, the common preprocessing steps, and an overview of established techniques such as manual coding, dictionary-based approaches, supervised machine learning, and unsupervised topic modeling. Subsequently, the chapter delves into the core ideas behind deep learning, including neural networks, word embeddings, and advanced architectures like RNNs and Transformers. The theoretical discussions are complemented by a practical, hands-on exercise in Python, where we will construct and train a basic neural network for sentiment classification, directly applying the concepts learned. This foundational knowledge is essential for social scientists looking to leverage computational tools for analyzing large-scale text data in their research. The first session of the day, from 08:30 to 10:00, will cover a welcome, an outline of the course structure and logistics, an introduction round, and a recapitulation of foundational text analysis concepts[cite: 3]. After a coffee break between 10:00 and 10:30, the second session, from 10:30 to 12:00, will focus on the basics of neural networks, core training concepts, and an introduction to text classification[cite: 3]. The course is structured as a combination of lectures and workshops[cite: 4]. Key learning objectives include understanding the fundamentals and evolution of Natural Language Processing (NLP), designing and implementing neural solutions for text-based problems, critically evaluating these methods for research applications, and gaining hands-on experience with current tools and frameworks[cite: 4]. Assessment for this course involves the completion of all work and 90% participation, which accounts for 2 credits, and course assignments, which also account for 2 credits[cite: 4, 5]. Course materials will primarily consist of articles provided daily and workbooks for assignments[cite: 5]. For any queries, the instructor can be contacted at sebastianus.bruinsma@chalmers.se[cite: 5]. As part of today’s learning, participants are encouraged to read “How To Make Causal Inferences Using Texts” by Egami et al. (2022), published in Science Advances[cite: 6]. When reading, it’s beneficial to focus on the sections discussing text as data, understand the relationship between text representation and causal inference, and consider how deep learning methods might impact causal analysis[cite: 6]. It is recommended to attempt these readings before the lecture[cite: 6]. For the practical components of this course, Python 3.10+ is recommended[cite: 7]. Essential libraries include numpy, pandas, and sklearn for general data handling and machine learning tasks; nltk, spacy, and gensim for traditional NLP tasks; tensorflow/keras or pytorch for building deep learning models; and transformers and datasets from HuggingFace for working with state-of-the-art transformer models[cite: 7]. Participants should check their environment setup using the python check_env.py script and ensure all libraries are installed and functional; Google Colab can be used as an alternative[cite: 7]. The workbooks for assignments will be provided as Jupyter Notebooks[cite: 7]. "],["recapitulation-of-text-analysis-fundamentals.html", "10.1 Recapitulation of Text Analysis Fundamentals", " 10.1 Recapitulation of Text Analysis Fundamentals Computational methods are increasingly employed in text analysis due to their ability to handle scale, ensuring reliability and consistency in analysis, and providing speed in processing large volumes of text[cite: 8]. These methods find common applications in diverse areas such as analyzing political communication (e.g., manifestos, speeches, social media content), media analysis (e.g., news framing, sentiment extraction), sociology (e.g., studying cultural trends, online communities), and survey analysis, particularly for open-ended questions[cite: 8, 9]. At a fundamental level, computers interpret texts as numerical data, often as counts of words using a model known as the “bag-of-words”[cite: 10]. To manage the high dimensionality and inherent complexities of textual data—a challenge often termed the “Curse of Dimensionality”—several preprocessing steps are necessary[cite: 10]. These include lowercasing all text to ensure uniformity, stemming or lemmatization to reduce words to their root form (e.g., “running” becomes “run”), removing common stop words (like “the”, “is”) and punctuation, tokenization which involves splitting text into individual units or tokens, and finally, creating a Document-Term Matrix (DTM) which represents word frequencies across all documents in a corpus[cite: 10]. 10.1.1 The Role of Manual Coding Manual content analysis, often considered the gold standard, remains crucial in many text analysis workflows[cite: 11]. It serves multiple purposes: generating labeled data essential for supervised machine learning models, validating the outputs of computational methods, and enabling in-depth qualitative analysis of smaller text samples[cite: 11]. The key steps in manual coding involve developing a clear codebook that outlines definitions and rules for annotation, training coders to ensure consistent application of the codebook, and assessing inter-coder reliability using statistical measures like Krippendorff’s \\(\\alpha\\) or Cohen’s \\(\\kappa\\) to quantify the level of agreement between coders[cite: 11, 12]. 10.1.2 Dictionary-Based Methods Dictionary-based methods represent a common approach in quantitative text analysis. These methods utilize lists of words, phrases, or patterns that are associated with specific concepts or categories of interest[cite: 13]. The core mechanism involves counting the occurrences of these dictionary terms within documents to assign a score for the concept the dictionary represents[cite: 13]. The advantages of this approach lie in its simplicity, transparency, and the ability to be theory-driven[cite: 13]. However, it also has limitations, such as being insensitive to context, requiring a well-curated and validated dictionary, and potentially missing nuances in language[cite: 13]. Dictionaries can be developed through two primary approaches: deductive, where one starts from existing theory or expert knowledge to define terms[cite: 14], or inductive, where terms are derived from manual coding or exploratory text analysis techniques like examining Keywords In Context (KWIC)[cite: 15]. Validating a dictionary is a critical step. Face validity assesses whether the terms intuitively make sense, often checked using KWIC analysis[cite: 16]. Internal validity involves checking the correlations between terms within the dictionary to ensure they collectively represent a coherent concept[cite: 17]. External validity is established by comparing the dictionary scores against manual codes or other external measures of the same concept[cite: 17]. 10.1.3 Supervised Machine Learning for Text Classification Supervised machine learning aims to train a model that can automatically classify documents into pre-defined categories[cite: 18]. The general workflow begins with preparing labeled data, where each document has associated features (derived from text) and a known category[cite: 18]. This dataset is then split into a training set and a test set[cite: 18]. A classification algorithm is chosen and trained on the training set, learning a mapping from features to categories[cite: 18, 21, 22]. The trained model is subsequently applied to the unseen test set to predict categories[cite: 18, 26]. Finally, the model’s performance is evaluated using metrics such as accuracy, precision, recall, and the F1-score, which assess how well its predictions match the actual categories in the test set[cite: 18]. Figure 10.1 visually outlines this process. Figure 10.1: Workflow of Supervised Machine Learning, depicting training and prediction phases. The learning algorithm uses training data and labels to produce a trained model, which then makes predictions on new data. 10.1.4 Unsupervised Learning for Topic Discovery In contrast to supervised methods, unsupervised learning aims to discover latent thematic structures within text data without relying on pre-defined labels or categories[cite: 29]. A prominent example is Latent Dirichlet Allocation (LDA). Simplified, LDA operates on the assumption that documents are composed of a mixture of topics, and each topic is characterized by a distribution of words[cite: 29]. The model’s objective is to infer these topic-word distributions (often denoted \\(\\beta\\)) and document-topic mixtures (often denoted \\(\\gamma\\)) that best explain the observed text data[cite: 29, 33, 34]. A key parameter in LDA is the number of topics, \\(K\\), which must be specified beforehand by the researcher[cite: 29]. The interpretation and validation of topics discovered through unsupervised methods like LDA are often subjective and require careful qualitative assessment[cite: 29]. Figure 10.2 illustrates how an unsupervised algorithm processes unlabeled documents to find underlying patterns, resulting in structures like topics as word mixtures and documents as topic mixtures. Figure 10.2: Unsupervised Learning Workflow (e.g., LDA), where an algorithm analyzes unlabeled input data to discover inherent structures, such as topics defined by word mixtures and documents represented by topic mixtures. [cite: 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] An overview of these traditional text analysis methods can often be visualized to show their relationships, as referenced by materials like Grimmer &amp; Stewart. ## Placeholder for image: figures/1_grimmerstewart.png "],["transitioning-to-deep-learning-for-text-analysis.html", "10.2 Transitioning to Deep Learning for Text Analysis", " 10.2 Transitioning to Deep Learning for Text Analysis While traditional methods offer valuable tools for text analysis, they often face limitations. These include difficulty in capturing nuance and subtle meanings in text, struggling with contextual understanding (such as sarcasm or irony), having a limited capacity to grasp complex relationships between words and ideas, and the possibility that pre-defined categories in supervised learning might miss unexpected or emergent patterns[cite: 40]. Furthermore, many traditional approaches require significant manual effort, for instance, in creating dictionaries or engineering features for machine learning models[cite: 40]. These challenges motivate the exploration of more advanced techniques like deep learning. Deep learning, a subfield of machine learning (ML), focuses on algorithms inspired by the structure and function of the human brain, known as Artificial Neural Networks (ANNs)[cite: 41]. The term “deep” signifies the use of multiple layers within these networks, enabling them to learn complex patterns and hierarchical features from data[cite: 42]. This hierarchical learning can be analogized to features being learned in stages: an initial layer might detect simple patterns (e.g., specific words in text or edges in an image)[cite: 43], a subsequent layer could combine these to identify more complex patterns (like common phrases or shapes)[cite: 44], and deeper layers can then integrate these to recognize abstract concepts (such as topics, sentiment, or objects)[cite: 45]. In the social sciences, deep learning offers compelling advantages, particularly for analyzing unstructured data like text from survey responses, social media, news articles, or political manifestos, and even image/video data from protest photos or satellite imagery[cite: 46]. Human behavior and social phenomena are rarely linear, and deep learning excels at modeling such complex non-linear relationships between variables[cite: 46]. A significant benefit is its capacity for feature learning, where the model automatically discovers relevant features from raw data, thereby reducing the need for extensive manual feature engineering—though domain knowledge remains crucial for interpretation and model design[cite: 46]. Deep learning models can also scale to predict social phenomena based on diverse and large data sources[cite: 46]. The “deep” aspect refers to the multiple layers of processing[cite: 47]. Each layer learns to recognize different features of the data, building understanding incrementally[cite: 47]. This is analogous to how humans process text: from characters to words, then phrases, sentences, and finally to overall meaning[cite: 53]. Figure 10.3 illustrates this layered abstraction. &lt;img src=“Introduction-to-Quantitative-Text-Analysis_files/figure-html/deep-layers-para-1.png” alt=“The”Deep” in Deep Learning: Layers of Feature Abstraction, from raw text input through simple and complex features to abstract concepts and finally meaning or category. [cite: 48, 49, 50, 51, 52, 53]” width=“100%” /&gt; Figure 10.3: The “Deep” in Deep Learning: Layers of Feature Abstraction, from raw text input through simple and complex features to abstract concepts and finally meaning or category. [cite: 48, 49, 50, 51, 52, 53] 10.2.1 Neural Networks: Core Components Neural networks are constructed from basic units called “neurons” or “nodes”[cite: 54]. Each neuron receives one or more inputs, performs a simple computation, and then produces an output[cite: 54]. This structure is inspired by biological neurons but is fundamentally a simplified mathematical model[cite: 59]. Figure 10.4 shows a schematic of a single neuron. Figure 10.4: Basic Neuron Structure, receiving multiple inputs and producing an output. [cite: 54, 55, 56, 57, 58] These neurons are organized into layers[cite: 60]. An Input Layer receives the raw data, such as the words in a text[cite: 61]. Hidden Layers then process this data through multiple computational steps; these are central to the “deep” aspect of deep learning[cite: 62]. Finally, an Output Layer produces the model’s result, for instance, a sentiment classification or a topic label[cite: 63]. Figure 10.5 depicts a simple network with input, hidden, and output layers. Figure 10.5: A Simple Multi-Layer Neural Network, showing an input layer, two hidden layers, and an output layer, with full connectivity between adjacent layers. [cite: 64, 65, 66, 67, 68, 69, 70] The connections between neurons are associated with numerical values called weights[cite: 71]. These weights are fundamental as they determine the influence one neuron’s output has on another’s input[cite: 71]. The process of learning in a neural network is essentially the adjustment of these weights to improve performance[cite: 71]. One can think of these weights as representing the strength of the connection between neurons[cite: 71, 73]. Learning occurs by training the network with a dataset containing examples and their corresponding correct labels[cite: 74]. The network makes predictions based on its current weights, compares these predictions to the true answers to calculate an “error,” and then slightly adjusts its weights to reduce this error[cite: 74]. This iterative process is repeated many times. For instance, if a network predicts a tweet like “Tax cuts for the rich are absurd. The gap is growing!” as being about ‘Policy’ when the correct label is ‘Concern’, it will adjust its weights to make ‘Concern’ a more likely prediction for similar tweets in the future[cite: 75, 74]. Figure 10.6 schematizes this iterative learning loop involving forward pass, error computation, and weight adjustment (backpropagation). Figure 10.6: The Learning Process in a Neural Network, illustrating the cycle of input, forward pass through the network, prediction, error computation against true labels, and weight adjustment via backpropagation. [cite: 76, 77, 78, 79, 80] 10.2.2 Representing Words: Word Embeddings Since computers do not understand words directly, words must be converted into a numerical format[cite: 81]. Deep learning models predominantly use Word Embeddings for this purpose, where words are represented as dense vectors—lists of numbers[cite: 81, 82, 83]. Figure 10.7 shows a word being mapped to such a vector. &lt;img src=“Introduction-to-Quantitative-Text-Analysis_files/figure-html/word-embedding-vector-para-1.png” alt=“A Word (e.g.,”equality”) being represented as a numerical vector through an embedding process. [cite: 81, 82, 83]” width=“70%” /&gt; Figure 10.7: A Word (e.g., “equality”) being represented as a numerical vector through an embedding process. [cite: 81, 82, 83] A key characteristic of effective word embeddings is that words with similar meanings are positioned closer to each other in the resulting multi-dimensional vector space[cite: 84]. This spatial arrangement allows the model to understand synonyms, related concepts, and even analogies, such as the classic “Man is to King as Woman is to Queen” relationship, which can be represented by vector arithmetic (e.g., vector(King) - vector(Man) + vector(Woman) \\(\\approx\\) vector(Queen))[cite: 84, 85, 86, 88, 89]. Figure 10.8 provides a simplified 2D illustration of this concept. Figure 10.8: A simplified 2D word embedding space where semantically similar words (e.g., King/Queen, Man/Woman, Cat/Dog) are located near each other. Dashed arrows illustrate relational similarities. [cite: 84, 85, 86, 87, 88, 89] The utility of word embeddings in social science research is increasingly recognized, with studies applying them to analyze ideological placement in parliamentary corpora, track the changing meanings of political concepts over time, investigate shifts in communication styles in political discourse, and provide guidance on their effective use in applied research[cite: 90]. 10.2.3 Handling Sequences: Recurrent Neural Networks (RNNs) A significant challenge with simpler models like bag-of-words is their disregard for word order, yet the meaning of text heavily depends on the sequence of words (e.g., “High taxes stifle opportunity” vs. “Opportunity stifled by high taxes”)[cite: 91]. Recurrent Neural Networks (RNNs) are specifically designed to handle such sequential data[cite: 91]. They possess a form of memory, allowing information from previous words in a sequence to influence the processing of subsequent words[cite: 91, 99]. RNNs process words one by one, maintaining a state or “memory” that carries forward contextual information[cite: 91, 98, 99]. Figure 10.9 shows how an RNN processes a sequence of words, with memory passed between units. However, basic RNNs can encounter difficulties, particularly with remembering information over very long sequences (the vanishing gradient problem) and capturing dependencies between words that are far apart in a sentence or document[cite: 92]. Figure 10.9: Recurrent Neural Network (RNN) processing a sequence of words (Word 1 to Word N). Each RNN unit processes a word and passes its memory state to the next unit, allowing information to flow through the sequence. [cite: 93, 94, 95, 96, 97, 98, 99, 100] 10.2.4 Advanced Architectures: Transformers and Attention To address some limitations of RNNs and further improve performance on complex NLP tasks, Transformer models were introduced, with the key innovative idea being the Attention mechanism[cite: 101]. Attention allows the model to weigh the importance of different words in the input text when processing information, rather than relying solely on sequential processing or fixed-length context windows[cite: 101]. This is analogous to how humans, when reading a sentence, quickly identify and focus on the most important words to understand the overall meaning[cite: 101]. For example, when classifying the sentiment of “This system is utterly unfair,” an attention mechanism can help the network strongly link “unfair” and “utterly” to “system,” thereby achieving a better contextual understanding for classification[cite: 102, 103, 104, 105, 106, 107]. Figure 10.10 illustrates this concept of words attending to other relevant words. &lt;img src=“Introduction-to-Quantitative-Text-Analysis_files/figure-html/attention-mechanism-para-1.png” alt=“Conceptual illustration of an Attention Mechanism, where words like”system”, “utterly”, and “This” attend to the word “unfair” to understand its context and impact. [cite: 102, 103, 104, 105, 106]” width=“80%” /&gt; Figure 10.10: Conceptual illustration of an Attention Mechanism, where words like “system”, “utterly”, and “This” attend to the word “unfair” to understand its context and impact. [cite: 102, 103, 104, 105, 106] The seminal paper “Attention Is All You Need” by Vaswani et al. (2017) introduced the Transformer architecture, which relies heavily on attention mechanisms and has become foundational for many state-of-the-art NLP models. ## Placeholder for image: figures/transfomers.png The development of NLP techniques, from early rule-based systems to modern deep learning architectures, represents a significant evolution in how machines process and understand human language. ## Placeholder for image: figures/timeline.png 10.2.5 Evaluating Deep Learning: Advantages and Challenges Deep learning models offer several advantages for text analysis. They can discover latent concepts, uncovering hidden themes and meanings within text that might not be apparent through other methods[cite: 108]. Their ability to model complexity allows them to uncover subtle patterns and interactions in large, unstructured text datasets[cite: 108]. These capabilities mean they can analyze sentiment, emotion, ideology, framing, and narratives in a more nuanced manner than traditional techniques and can learn highly complex, non-linear relationships in data[cite: 108]. Furthermore, deep learning often automates feature extraction, reducing the need for extensive manual feature engineering[cite: 108]. Despite these strengths, deep learning also presents challenges. Models can act as a “black box,” making their decision-making processes difficult to interpret and understand[cite: 109]. They typically require large amounts of data for effective training[cite: 109]. The cost associated with training deep models can be substantial, requiring significant computing resources and time[cite: 109]. A critical concern is bias, as models can learn and even amplify biases present in the training data[cite: 109]. Finally, implementing and fine-tuning these models effectively often requires considerable technical expertise[cite: 109]. "],["practical-exercise-basic-text-classification-with-deep-learning-in-python.html", "10.3 Practical Exercise: Basic Text Classification with Deep Learning in Python", " 10.3 Practical Exercise: Basic Text Classification with Deep Learning in Python Having discussed the theoretical foundations of deep learning for text, we now transition to a practical application. This exercise will guide you through implementing a simple deep learning model, specifically a feedforward neural network, to classify text sentiment using the Keras API within TensorFlow. While we use a standard dataset of movie reviews for its clarity and pre-labeled nature[cite: 116], the techniques and workflow are directly transferable to a wide array of social science text analysis tasks[cite: 110]. For instance, these methods can be adapted for analyzing sentiment in political tweets or news articles, detecting stances in parliamentary debates or online forum discussions, coding open-ended survey responses, or identifying thematic content in interview transcripts[cite: 111]. Understanding how to numerically represent text and build classifiers is a crucial skill for analyzing large text corpora in social research[cite: 111]. 10.3.1 1. Setup: Importing Libraries Our first step is to import the necessary Python libraries. We will use tensorflow and its high-level API keras for building and training our deep learning model[cite: 112]. numpy will be employed for numerical operations[cite: 113], and pandas could be used for more complex data manipulation, though Keras datasets often load directly in a usable format[cite: 113]. scikit-learn offers tools for tasks like splitting data and evaluating model metrics[cite: 114], although for this specific exercise, Keras functionalities will cover most needs. Optionally, matplotlib can be used for visualizing results, such as training progress[cite: 114]. import numpy as np import pandas as pd import tensorflow as tf from tensorflow import keras from tensorflow.keras.datasets import imdb from tensorflow.keras.preprocessing.sequence import pad_sequences from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Embedding, Flatten, Dense # from sklearn.model_selection import train_test_split # Listed in preamble, not used in the script body [cite: 114] # Optional: for plotting # import matplotlib.pyplot as plt print(&quot;TensorFlow Version:&quot;, tf.__version__) 10.3.2 2. Load Data: IMDB Movie Reviews For this exercise, we will use the well-known IMDB movie review dataset, which Keras conveniently provides[cite: 116]. This dataset comprises 50,000 movie reviews, each pre-labeled as either positive (represented by 1) or negative (represented by 0)[cite: 116]. When loading the data, we specify num_words=VOCAB_SIZE (e.g., 10,000) to limit our vocabulary to the top VOCAB_SIZE most frequent words in the dataset[cite: 117, 118]. Words that fall outside this selected vocabulary will be treated as “unknown” tokens[cite: 118]. This is a common preprocessing step to manage vocabulary size and focus on more informative words. # --- Parameters --- VOCAB_SIZE = 10000 # How many unique words to consider [cite: 118] # --- End Parameters --- print(f&quot;Loading IMDB dataset, keeping top {VOCAB_SIZE} words...&quot;) (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=VOCAB_SIZE) print(&quot;--------------------&quot;) print(f&quot;Training entries: {len(train_data)}, labels: {len(train_labels)}&quot;) print(f&quot;Test entries: {len(test_data)}, labels: {len(test_labels)}&quot;) print(&quot;--------------------&quot;) print(&quot;Example review (sequence of word indices):&quot;) print(train_data[0]) print(&quot;--------------------&quot;) print(&quot;Example label (0=Negative, 1=Positive):&quot;) print(train_labels[0]) It is important to understand the format of this data. Each review is already preprocessed into a sequence of integers[cite: 119]. Each integer corresponds to a specific word in a pre-defined dictionary or vocabulary[cite: 119]. For exploration, we can decode these integer sequences back into human-readable words, although this step is not required for model training itself[cite: 120]. The imdb.get_word_index() function provides the word-to-index mapping, to which we add special tokens like &lt;PAD&gt; (for padding), &lt;START&gt; (to mark the beginning), &lt;UNK&gt; (for unknown words), and an unused token[cite: 120]. # A dictionary mapping words to an integer index [cite: 120] word_index = imdb.get_word_index() # The first indices are reserved; shift original indices by 3 [cite: 120] word_index = {k:(v+3) for k,v in word_index.items()} word_index[&quot;&lt;PAD&gt;&quot;] = 0 # Padding token [cite: 120] word_index[&quot;&lt;START&gt;&quot;] = 1 # Start token [cite: 120] word_index[&quot;&lt;UNK&gt;&quot;] = 2 # Unknown token [cite: 120] word_index[&quot;&lt;UNUSED&gt;&quot;] = 3 # [cite: 120] reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) def decode_review(text_indices): return &#39; &#39;.join([reverse_word_index.get(i, &#39;?&#39;) for i in text_indices]) print(&quot;Decoded first review:&quot;) print(decode_review(train_data[0])) 10.3.3 3. Preprocessing: Padding Sequences Neural networks generally require inputs to have a consistent shape and size[cite: 121]. However, our movie reviews naturally vary in length (i.e., they have different numbers of words)[cite: 121]. To address this, we must standardize the length of each review sequence using a technique called padding[cite: 121, 122]. We select a MAX_SEQUENCE_LENGTH (e.g., 250 words)[cite: 126]. Reviews shorter than this maximum length will be padded with a special value (0, which we mapped to the &lt;PAD&gt; token) to reach the desired length[cite: 123]. Conversely, reviews longer than MAX_SEQUENCE_LENGTH will be truncated, meaning words beyond this limit will be removed[cite: 124]. We can choose to apply padding and truncation either at the beginning (padding='pre', truncating='pre') or at the end (padding='post', truncating='post') of the sequences[cite: 125]. While post-padding is used here, pre-padding is often slightly preferred for certain sequence models that we might encounter later in the course[cite: 125]. # --- Parameters --- MAX_SEQUENCE_LENGTH = 250 # Max number of words per review to consider [cite: 126] PADDING_TYPE = &#39;post&#39; # Pad/truncate at the &#39;pre&#39; or &#39;post&#39; end [cite: 125, 127] TRUNCATING_TYPE = &#39;post&#39; # Truncate from &#39;pre&#39; or &#39;post&#39; [cite: 125, 127] # --- End Parameters --- print(&quot;Padding/Truncating sequences...&quot;) train_data_padded = pad_sequences(train_data, maxlen=MAX_SEQUENCE_LENGTH, padding=PADDING_TYPE, truncating=TRUNCATING_TYPE) # [cite: 127] test_data_padded = pad_sequences(test_data, maxlen=MAX_SEQUENCE_LENGTH, padding=PADDING_TYPE, truncating=TRUNCATING_TYPE) # [cite: 128] print(&quot;--------------------&quot;) print(&quot;Shape of original train data entry:&quot;, train_data[0].shape) # Example to show change print(&quot;Shape of padded train data entry:&quot;, train_data_padded[0].shape) print(&quot;--------------------&quot;) print(&quot;Example Padded Review (scroll right to see potential padding):&quot;) print(train_data_padded[0]) As a good practice, we should also ensure our labels (positive/negative sentiment) are in the correct data type, typically NumPy arrays of type float32, for compatibility with loss functions used during model training[cite: 129]. train_labels = np.asarray(train_labels).astype(&#39;float32&#39;) # [cite: 129] test_labels = np.asarray(test_labels).astype(&#39;float32&#39;) # [cite: 129] print(&quot;--------------------&quot;) print(&quot;Data types check:&quot;) print(&quot;Padded Train Data:&quot;, train_data_padded.dtype) print(&quot;Train Labels:&quot;, train_labels.dtype) 10.3.4 4. Build the Model Now, we define the architecture of our neural network using the Keras Sequential API, which allows us to build models layer-by-layer[cite: 130]. For this exercise, we will construct a simple feedforward network consisting of an embedding layer, a flatten layer, a hidden dense layer, and an output dense layer[cite: 130]. The Embedding Layer is a crucial component for NLP tasks[cite: 131]. It takes the integer-encoded vocabulary (with VOCAB_SIZE unique words) as input[cite: 131]. Its primary function is to learn a dense vector representation, known as an “embedding,” for each word in the vocabulary[cite: 132]. The dimensionality of these learned vectors is specified by EMBEDDING_DIM (e.g., 16)[cite: 133, 143]. The output of this layer for a batch of sequences will have a shape of (batch_size, MAX_SEQUENCE_LENGTH, EMBEDDING_DIM)[cite: 134]. Instead of using sparse representations like one-hot encoding or TF-IDF vectors, embeddings learn meaningful, lower-dimensional representations where words with similar meanings tend to have similar vector representations[cite: 134]. We will explore embeddings in more detail later[cite: 135]. The Flatten Layer follows the embedding layer. Its purpose is to transform the 3D output of the Embedding layer (which is sequence_length * embedding_dim for each review) into a 1D vector[cite: 136]. This flattening is necessary to make the data suitable for input into standard Dense (fully connected) layers[cite: 136]. It’s important to note that this layer discards any sequence information present in the embeddings by collapsing the sequence dimension[cite: 136]. Alternatives like GlobalAveragePooling1D or GlobalMaxPooling1D layers are often better choices as they aggregate information across the sequence dimension, thereby retaining some information regardless of word position, and you might experiment with these later[cite: 137]. Next is a Dense Layer, serving as a hidden layer in our network. This is a standard fully connected layer. We use the ReLU (Rectified Linear Unit) activation function, which is a common choice for hidden layers[cite: 138, 139]. This layer learns higher-level combinations of features from the flattened word embeddings[cite: 139]. The number of neurons in this layer is set by HIDDEN_LAYER_UNITS[cite: 143]. Finally, the Output Dense Layer consists of a single neuron and uses a sigmoid activation function[cite: 140, 141]. The sigmoid function squashes its input into a range between 0 and 1, making it ideal for binary classification tasks like ours[cite: 141]. The output can be interpreted as the probability of the review being positive[cite: 141]. Connecting this to social science applications, one can conceptualize the Embedding layer as learning the ‘meaning’ of words within the context of the data, and the subsequent Dense layers as learning how combinations of these learned word meanings relate to the outcome variable (e.g., positive or negative sentiment)[cite: 142]. # --- Parameters --- EMBEDDING_DIM = 16 # Dimension of the word vectors learned by Embedding layer [cite: 143] HIDDEN_LAYER_UNITS = 16 # Number of neurons in the hidden Dense layer [cite: 143] # --- End Parameters --- print(&quot;Building the model...&quot;) model = Sequential([ # 1. Embedding Layer Embedding(input_dim=VOCAB_SIZE, # Size of the vocabulary [cite: 131] output_dim=EMBEDDING_DIM, # Dimension of the embedding vector for each word [cite: 133] input_length=MAX_SEQUENCE_LENGTH # Length of input sequences [cite: 144] ), # 2. Flatten Layer (or try GlobalAveragePooling1D()) [cite: 136] Flatten(), # GlobalAveragePooling1D(), # Alternative to Flatten [cite: 137] # 3. Hidden Dense Layer Dense(units=HIDDEN_LAYER_UNITS, activation=&#39;relu&#39;), # [cite: 138, 139] # 4. Output Dense Layer Dense(units=1, activation=&#39;sigmoid&#39;) # Sigmoid for binary classification [cite: 140, 141] ]) print(&quot;--------------------&quot;) model.summary() # Print a summary of the model architecture 10.3.5 5. Compile the Model Before we can train our network, we need to configure its learning process using the model.compile() method[cite: 145]. This involves specifying three key components: Optimizer: This is the algorithm that will be used to update the model’s weights based on the training data and the calculated loss. adam (Adaptive Moment Estimation) is a widely used and generally effective optimizer that often provides good results with default settings[cite: 146]. This relates to the concept of Gradient Descent discussed in the lectures[cite: 146]. Loss Function: This function measures how inaccurate the model’s predictions are compared to the true labels during training[cite: 147]. For binary (0/1) classification problems where the output layer uses a sigmoid activation function, binary_crossentropy is the standard and appropriate loss function[cite: 148]. Metrics: These are used to monitor the training and testing steps. While the loss function is used to guide the learning process (weight updates), metrics provide a human-understandable measure of model performance. We will use accuracy, which calculates the proportion of correctly classified reviews[cite: 149]. print(&quot;Compiling the model...&quot;) model.compile(optimizer=&#39;adam&#39;, # [cite: 146] loss=&#39;binary_crossentropy&#39;, # [cite: 148] metrics=[&#39;accuracy&#39;]) # [cite: 149] print(&quot;Model compiled.&quot;) 10.3.6 6. Train the Model With the model architecture defined and compiled, we can now train it using the model.fit() method[cite: 151]. This method takes our padded training data (train_data_padded) and corresponding training labels (train_labels) as input[cite: 151]. Several parameters control the training process: * epochs: This specifies the number of times the model will iterate over the entire training dataset[cite: 152]. One epoch means every sample in the training data has been used once to update the model’s weights. * batch_size: This defines the number of training samples that are processed before the model’s weights are updated within each epoch[cite: 153]. For example, if the batch size is 512, the model processes 512 reviews, calculates the average loss, and then updates its weights. * validation_data: This is crucial for monitoring the model’s performance on data it has not been trained on[cite: 154]. We provide our padded test data (test_data_padded) and test labels (test_labels) here. At the end of each epoch, the model evaluates its loss and any specified metrics (like accuracy) on this validation set[cite: 154]. Importantly, the model does not train on this validation data; it is only used for evaluation[cite: 155]. This helps us detect a common issue known as overfitting[cite: 155]. Overfitting occurs when the model performs very well on the training data but poorly on unseen data (like the validation set or, later, the test set)[cite: 156]. It essentially means the model has learned the training data “too well,” including its noise and specific quirks, rather than generalizable patterns. Signs of overfitting include the training accuracy continuing to increase while the validation accuracy plateaus or even starts to decrease[cite: 157]. # --- Parameters --- NUM_EPOCHS = 10 # Number of times to iterate over the entire training dataset [cite: 152, 158] BATCH_SIZE = 512 # Number of samples processed before weight update [cite: 153, 158] # --- End Parameters --- print(&quot;Training the model...&quot;) history = model.fit(train_data_padded, train_labels, # [cite: 151] epochs=NUM_EPOCHS, # [cite: 152] batch_size=BATCH_SIZE, # [cite: 153] validation_data=(test_data_padded, test_labels), # [cite: 154] verbose=1 # Set to 1 for progress bar, 2 for less output per epoch, 0 for silent [cite: 159] ) print(&quot;Model training finished.&quot;) Visualizing the training process by plotting the training and validation loss, as well as training and validation accuracy, over epochs is a highly recommended practice[cite: 160]. These plots make it much easier to understand how the training is progressing and to spot overfitting or other training issues[cite: 160]. # # Optional: Plotting - uncomment to run [cite: 160] # import matplotlib.pyplot as plt # history_dict = history.history # acc = history_dict[&#39;accuracy&#39;] # val_acc = history_dict[&#39;val_accuracy&#39;] # loss = history_dict[&#39;loss&#39;] # val_loss = history_dict[&#39;val_loss&#39;] # epochs_range = range(1, NUM_EPOCHS + 1) # plt.figure(figsize=(12, 5)) # plt.subplot(1, 2, 1) # plt.plot(epochs_range, loss, &#39;bo&#39;, label=&#39;Training loss&#39;) # plt.plot(epochs_range, val_loss, &#39;b&#39;, label=&#39;Validation loss&#39;) # plt.title(&#39;Training and validation loss&#39;) # plt.xlabel(&#39;Epochs&#39;) # plt.ylabel(&#39;Loss&#39;) # plt.legend() # plt.subplot(1, 2, 2) # plt.plot(epochs_range, acc, &#39;bo&#39;, label=&#39;Training acc&#39;) # plt.plot(epochs_range, val_acc, &#39;b&#39;, label=&#39;Validation acc&#39;) # plt.title(&#39;Training and validation accuracy&#39;) # plt.xlabel(&#39;Epochs&#39;) # plt.ylabel(&#39;Accuracy&#39;) # plt.legend() # plt.tight_layout() # plt.show() 10.3.7 7. Evaluate the Model After training, the final step is to evaluate the model’s performance on the test set (test_data_padded and test_labels). This dataset has been kept separate throughout the training process and provides an unbiased estimate of how well the model is likely to perform on new, unseen data[cite: 161]. print(&quot;Evaluating model on test data...&quot;) loss, accuracy = model.evaluate(test_data_padded, test_labels, verbose=0) # [cite: 161] print(&quot;--------------------&quot;) print(f&quot;Test Loss: {loss:.4f}&quot;) print(f&quot;Test Accuracy: {accuracy:.4f}&quot;) print(&quot;--------------------&quot;) 10.3.8 8. Discussion &amp; Next Steps Having completed this exercise, you have successfully trained your first deep learning model for text classification[cite: 162, 163]. This achievement forms a solid foundation for tackling more complex NLP tasks using deep learning. "],["exercises-and-further-exploration.html", "10.4 Exercises and Further Exploration", " 10.4 Exercises and Further Exploration The completion of this initial model opens up several avenues for discussion and further experimentation, which are crucial for deepening your understanding. Baseline Comparison: How did the achieved test accuracy compare to a simple baseline, such as random guessing (which would be 50% for a balanced binary classification task)? [cite: 163] Overfitting Assessment: If you generated and examined the training plots, did you observe signs of overfitting? [cite: 164] Recall that a classic sign is when validation accuracy peaks and then potentially decreases, even as training accuracy continues to rise[cite: 165]. What strategies could be employed to mitigate overfitting if it was observed? Hyperparameter Sensitivity: Consider the impact of VOCAB_SIZE and MAX_SEQUENCE_LENGTH[cite: 166]. How might changing these parameters affect model performance, training time, and memory usage? For instance, would a significantly larger VOCAB_SIZE always be beneficial? Model Architecture Limitations: Reflect on the limitations of this relatively simple model[cite: 167]. The Flatten layer, for example, discards word order information[cite: 136, 167]. How might this affect its ability to understand more nuanced text where word order is critical? Application to Social Science Data: Outline how this workflow (data loading, preprocessing, model building, compilation, training, and evaluation) could be adapted for a specific social science dataset you are familiar with or interested in (e.g., classifying political manifestos by ideology, detecting frames in news articles, or categorizing open-ended survey responses for themes)[cite: 168]. What specific challenges might arise when working with real-world social science text data? Consider issues such as data cleanliness (noise, misspellings), variations in text length and style, the potential for more numerous or complex labels (multiclass or multilabel classification), and class imbalance in categorical data[cite: 169]. Experimentation and Model Improvement: Modify the EMBEDDING_DIM parameter[cite: 170]. Does increasing or decreasing the embedding dimension significantly impact performance? Is there a point of diminishing returns? Adjust the HIDDEN_LAYER_UNITS or experiment with adding another Dense hidden layer[cite: 171]. How does model complexity affect performance and the risk of overfitting? Replace the Flatten() layer with keras.layers.GlobalAveragePooling1D()[cite: 172]. Does this change improve accuracy? Why might GlobalAveragePooling1D be a better choice for some text classification tasks? (Hint: It aggregates embedding vectors across the sequence, which can be more robust to variations in sequence length and word position than simply flattening [cite: 137, 172]). Vary the NUM_EPOCHS for training[cite: 173]. Observe the impact on both training and validation accuracy. How does this relate to overfitting or underfitting? Experiment with different values for VOCAB_SIZE and MAX_SEQUENCE_LENGTH[cite: 174]. How do these choices trade off information retention versus computational efficiency? This exercise provides a crucial stepping stone. The understanding gained here will be invaluable as we progress to more sophisticated architectures like Recurrent Neural Networks (RNNs), Long Short-Term Memory networks (LSTMs), and Transformers, which are specifically designed to better capture sequential information and long-range dependencies in text[cite: 174]. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
