<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>10.3 Practical Exercise: Basic Text Classification with Deep Learning in Python | Introduction to Quantitative Text Analysis</title>
  <meta name="description" content="10.3 Practical Exercise: Basic Text Classification with Deep Learning in Python | Introduction to Quantitative Text Analysis" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="10.3 Practical Exercise: Basic Text Classification with Deep Learning in Python | Introduction to Quantitative Text Analysis" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="10.3 Practical Exercise: Basic Text Classification with Deep Learning in Python | Introduction to Quantitative Text Analysis" />
  
  
  

<meta name="author" content="Kostas Gemenis and Bastiaan Bruinsma" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="transitioning-to-deep-learning-for-text-analysis.html"/>
<link rel="next" href="exercises-and-further-exploration.html"/>
<script src="assets/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="assets/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="assets/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="assets/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Quantitative Text Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome!</a></li>
<li class="chapter" data-level="1" data-path="preliminaries.html"><a href="preliminaries.html"><i class="fa fa-check"></i><b>1</b> Preliminaries</a>
<ul>
<li class="chapter" data-level="1.1" data-path="installing-r.html"><a href="installing-r.html"><i class="fa fa-check"></i><b>1.1</b> Installing R</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="installing-r.html"><a href="installing-r.html#windows"><i class="fa fa-check"></i><b>1.1.1</b> Windows</a></li>
<li class="chapter" data-level="1.1.2" data-path="installing-r.html"><a href="installing-r.html#linux"><i class="fa fa-check"></i><b>1.1.2</b> Linux</a></li>
<li class="chapter" data-level="1.1.3" data-path="installing-r.html"><a href="installing-r.html#macos"><i class="fa fa-check"></i><b>1.1.3</b> macOS</a></li>
<li class="chapter" data-level="1.1.4" data-path="installing-r.html"><a href="installing-r.html#cloud"><i class="fa fa-check"></i><b>1.1.4</b> Cloud</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="installing-packages.html"><a href="installing-packages.html"><i class="fa fa-check"></i><b>1.2</b> Installing Packages</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="installing-packages.html"><a href="installing-packages.html#cran"><i class="fa fa-check"></i><b>1.2.1</b> CRAN</a></li>
<li class="chapter" data-level="1.2.2" data-path="installing-packages.html"><a href="installing-packages.html#github"><i class="fa fa-check"></i><b>1.2.2</b> GitHub</a></li>
<li class="chapter" data-level="1.2.3" data-path="installing-packages.html"><a href="installing-packages.html#writing-packages"><i class="fa fa-check"></i><b>1.2.3</b> Writing Packages</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="required.html"><a href="required.html"><i class="fa fa-check"></i><b>1.3</b> Required Packages</a></li>
<li class="chapter" data-level="1.4" data-path="troubleshooting.html"><a href="troubleshooting.html"><i class="fa fa-check"></i><b>1.4</b> Troubleshooting</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>2</b> Background</a>
<ul>
<li class="chapter" data-level="2.1" data-path="concepts.html"><a href="concepts.html"><i class="fa fa-check"></i><b>2.1</b> Concepts</a></li>
<li class="chapter" data-level="2.2" data-path="workflow.html"><a href="workflow.html"><i class="fa fa-check"></i><b>2.2</b> Workflow</a></li>
<li class="chapter" data-level="2.3" data-path="validation.html"><a href="validation.html"><i class="fa fa-check"></i><b>2.3</b> Validation</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="validation.html"><a href="validation.html#validity"><i class="fa fa-check"></i><b>2.3.1</b> Validity</a></li>
<li class="chapter" data-level="2.3.2" data-path="validation.html"><a href="validation.html#reliability"><i class="fa fa-check"></i><b>2.3.2</b> Reliability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="import.html"><a href="import.html"><i class="fa fa-check"></i><b>3</b> Text in R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>3.1</b> Basics</a></li>
<li class="chapter" data-level="3.2" data-path="import-.html"><a href="import-.html"><i class="fa fa-check"></i><b>3.2</b> Import .txt</a></li>
<li class="chapter" data-level="3.3" data-path="import-.html"><a href="import-.html#import-.pdf"><i class="fa fa-check"></i><b>3.3</b> Import .pdf</a></li>
<li class="chapter" data-level="3.4" data-path="import-.html"><a href="import-.html#import-.csv"><i class="fa fa-check"></i><b>3.4</b> Import .csv</a></li>
<li class="chapter" data-level="3.5" data-path="import-from-an-api.html"><a href="import-from-an-api.html"><i class="fa fa-check"></i><b>3.5</b> Import from an API</a></li>
<li class="chapter" data-level="3.6" data-path="import-using-web-scraping.html"><a href="import-using-web-scraping.html"><i class="fa fa-check"></i><b>3.6</b> Import using Web Scraping</a></li>
<li class="chapter" data-level="3.7" data-path="import-json-and-xml.html"><a href="import-json-and-xml.html"><i class="fa fa-check"></i><b>3.7</b> Import JSON and XML</a></li>
<li class="chapter" data-level="3.8" data-path="import-from-databases.html"><a href="import-from-databases.html"><i class="fa fa-check"></i><b>3.8</b> Import from Databases</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="describe.html"><a href="describe.html"><i class="fa fa-check"></i><b>4</b> Describe</a>
<ul>
<li class="chapter" data-level="4.1" data-path="corpus-and-dfm.html"><a href="corpus-and-dfm.html"><i class="fa fa-check"></i><b>4.1</b> Corpus and DFM</a></li>
<li class="chapter" data-level="4.2" data-path="text-pre-processing.html"><a href="text-pre-processing.html"><i class="fa fa-check"></i><b>4.2</b> Text Pre-processing</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="text-pre-processing.html"><a href="text-pre-processing.html#tokenisation-and-initial-cleaning"><i class="fa fa-check"></i><b>4.2.1</b> Tokenisation and Initial Cleaning</a></li>
<li class="chapter" data-level="4.2.2" data-path="text-pre-processing.html"><a href="text-pre-processing.html#lower-casing"><i class="fa fa-check"></i><b>4.2.2</b> Lower-casing</a></li>
<li class="chapter" data-level="4.2.3" data-path="text-pre-processing.html"><a href="text-pre-processing.html#stopword-removal"><i class="fa fa-check"></i><b>4.2.3</b> Stopword Removal</a></li>
<li class="chapter" data-level="4.2.4" data-path="text-pre-processing.html"><a href="text-pre-processing.html#n-grams-and-collocations"><i class="fa fa-check"></i><b>4.2.4</b> N-grams and Collocations</a></li>
<li class="chapter" data-level="4.2.5" data-path="text-pre-processing.html"><a href="text-pre-processing.html#stemming-and-lemmatisation"><i class="fa fa-check"></i><b>4.2.5</b> Stemming and Lemmatisation</a></li>
<li class="chapter" data-level="4.2.6" data-path="text-pre-processing.html"><a href="text-pre-processing.html#removing-sparse-features-dfm-trimming"><i class="fa fa-check"></i><b>4.2.6</b> Removing Sparse Features (DFM Trimming)</a></li>
<li class="chapter" data-level="4.2.7" data-path="text-pre-processing.html"><a href="text-pre-processing.html#additional-pre-processing"><i class="fa fa-check"></i><b>4.2.7</b> Additional Pre-Processing</a></li>
<li class="chapter" data-level="4.2.8" data-path="text-pre-processing.html"><a href="text-pre-processing.html#evaluating-pre-processing"><i class="fa fa-check"></i><b>4.2.8</b> Evaluating Pre-Processing</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="descriptives-and-visualisations.html"><a href="descriptives-and-visualisations.html"><i class="fa fa-check"></i><b>4.3</b> Descriptives and Visualisations</a></li>
<li class="chapter" data-level="4.4" data-path="text-statistics.html"><a href="text-statistics.html"><i class="fa fa-check"></i><b>4.4</b> Text Statistics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="text-statistics.html"><a href="text-statistics.html#summary"><i class="fa fa-check"></i><b>4.4.1</b> Summary</a></li>
<li class="chapter" data-level="4.4.2" data-path="text-statistics.html"><a href="text-statistics.html#frequencies"><i class="fa fa-check"></i><b>4.4.2</b> Frequencies</a></li>
<li class="chapter" data-level="4.4.3" data-path="text-statistics.html"><a href="text-statistics.html#lexical-diversity"><i class="fa fa-check"></i><b>4.4.3</b> Lexical diversity</a></li>
<li class="chapter" data-level="4.4.4" data-path="text-statistics.html"><a href="text-statistics.html#readability"><i class="fa fa-check"></i><b>4.4.4</b> Readability</a></li>
<li class="chapter" data-level="4.4.5" data-path="text-statistics.html"><a href="text-statistics.html#similarity-and-distance"><i class="fa fa-check"></i><b>4.4.5</b> Similarity and Distance</a></li>
<li class="chapter" data-level="4.4.6" data-path="text-statistics.html"><a href="text-statistics.html#keyness"><i class="fa fa-check"></i><b>4.4.6</b> Keyness</a></li>
<li class="chapter" data-level="4.4.7" data-path="text-statistics.html"><a href="text-statistics.html#entropy"><i class="fa fa-check"></i><b>4.4.7</b> Entropy</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>4.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="dictionary-analysis.html"><a href="dictionary-analysis.html"><i class="fa fa-check"></i><b>5</b> Dictionary Analysis</a>
<ul>
<li class="chapter" data-level="5.1" data-path="classical-dictionary-analysis.html"><a href="classical-dictionary-analysis.html"><i class="fa fa-check"></i><b>5.1</b> Classical Dictionary Analysis</a></li>
<li class="chapter" data-level="5.2" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html"><i class="fa fa-check"></i><b>5.2</b> Sentiment Analysis</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#movie-reviews"><i class="fa fa-check"></i><b>5.2.1</b> Movie Reviews</a></li>
<li class="chapter" data-level="5.2.2" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#twitter"><i class="fa fa-check"></i><b>5.2.2</b> Twitter</a></li>
<li class="chapter" data-level="5.2.3" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#vader"><i class="fa fa-check"></i><b>5.2.3</b> VADER</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>5.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="scaling.html"><a href="scaling.html"><i class="fa fa-check"></i><b>6</b> Scaling Methods</a>
<ul>
<li class="chapter" data-level="6.1" data-path="wordscores.html"><a href="wordscores.html"><i class="fa fa-check"></i><b>6.1</b> Wordscores</a></li>
<li class="chapter" data-level="6.2" data-path="wordfish.html"><a href="wordfish.html"><i class="fa fa-check"></i><b>6.2</b> Wordfish</a></li>
<li class="chapter" data-level="6.3" data-path="correspondence-analysis.html"><a href="correspondence-analysis.html"><i class="fa fa-check"></i><b>6.3</b> Correspondence Analysis</a></li>
<li class="chapter" data-level="6.4" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>6.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="supervised-methods.html"><a href="supervised-methods.html"><i class="fa fa-check"></i><b>7</b> Supervised Methods</a>
<ul>
<li class="chapter" data-level="7.1" data-path="support-vector-machines-svm.html"><a href="support-vector-machines-svm.html"><i class="fa fa-check"></i><b>7.1</b> Support Vector Machines (SVM)</a></li>
<li class="chapter" data-level="7.2" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>7.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="7.3" data-path="naive-bayes-nb.html"><a href="naive-bayes-nb.html"><i class="fa fa-check"></i><b>7.3</b> Naive Bayes (NB)</a></li>
<li class="chapter" data-level="7.4" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>7.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="unsupervised-methods.html"><a href="unsupervised-methods.html"><i class="fa fa-check"></i><b>8</b> Unsupervised Methods</a>
<ul>
<li class="chapter" data-level="8.1" data-path="latent-dirichlet-allocation-lda.html"><a href="latent-dirichlet-allocation-lda.html"><i class="fa fa-check"></i><b>8.1</b> Latent Dirichlet Allocation (LDA)</a></li>
<li class="chapter" data-level="8.2" data-path="seeded-latent-dirichlet-allocation-slda.html"><a href="seeded-latent-dirichlet-allocation-slda.html"><i class="fa fa-check"></i><b>8.2</b> Seeded Latent Dirichlet Allocation (sLDA)</a></li>
<li class="chapter" data-level="8.3" data-path="structural-topic-model-stm.html"><a href="structural-topic-model-stm.html"><i class="fa fa-check"></i><b>8.3</b> Structural Topic Model (STM)</a></li>
<li class="chapter" data-level="8.4" data-path="latent-semantic-analysis-lsa.html"><a href="latent-semantic-analysis-lsa.html"><i class="fa fa-check"></i><b>8.4</b> Latent Semantic Analysis (LSA)</a></li>
<li class="chapter" data-level="8.5" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>8.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="day1-intro-fundamentals.html"><a href="day1-intro-fundamentals.html"><i class="fa fa-check"></i><b>9</b> Advanced Quantitative Text Analysis: Day 1: Introduction &amp; Fundamentals</a></li>
<li class="chapter" data-level="10" data-path="day1-intro-fundamentals.html"><a href="day1-intro-fundamentals.html#day1-intro-fundamentals"><i class="fa fa-check"></i><b>10</b> Advanced Quantitative Text Analysis: Day 1: Introduction &amp; Fundamentals</a>
<ul>
<li class="chapter" data-level="10.1" data-path="recapitulation-of-text-analysis-fundamentals.html"><a href="recapitulation-of-text-analysis-fundamentals.html"><i class="fa fa-check"></i><b>10.1</b> Recapitulation of Text Analysis Fundamentals</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="recapitulation-of-text-analysis-fundamentals.html"><a href="recapitulation-of-text-analysis-fundamentals.html#the-role-of-manual-coding"><i class="fa fa-check"></i><b>10.1.1</b> The Role of Manual Coding</a></li>
<li class="chapter" data-level="10.1.2" data-path="recapitulation-of-text-analysis-fundamentals.html"><a href="recapitulation-of-text-analysis-fundamentals.html#dictionary-based-methods"><i class="fa fa-check"></i><b>10.1.2</b> Dictionary-Based Methods</a></li>
<li class="chapter" data-level="10.1.3" data-path="recapitulation-of-text-analysis-fundamentals.html"><a href="recapitulation-of-text-analysis-fundamentals.html#supervised-machine-learning-for-text-classification"><i class="fa fa-check"></i><b>10.1.3</b> Supervised Machine Learning for Text Classification</a></li>
<li class="chapter" data-level="10.1.4" data-path="recapitulation-of-text-analysis-fundamentals.html"><a href="recapitulation-of-text-analysis-fundamentals.html#unsupervised-learning-for-topic-discovery"><i class="fa fa-check"></i><b>10.1.4</b> Unsupervised Learning for Topic Discovery</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="transitioning-to-deep-learning-for-text-analysis.html"><a href="transitioning-to-deep-learning-for-text-analysis.html"><i class="fa fa-check"></i><b>10.2</b> Transitioning to Deep Learning for Text Analysis</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="transitioning-to-deep-learning-for-text-analysis.html"><a href="transitioning-to-deep-learning-for-text-analysis.html#neural-networks-core-components"><i class="fa fa-check"></i><b>10.2.1</b> Neural Networks: Core Components</a></li>
<li class="chapter" data-level="10.2.2" data-path="transitioning-to-deep-learning-for-text-analysis.html"><a href="transitioning-to-deep-learning-for-text-analysis.html#representing-words-word-embeddings"><i class="fa fa-check"></i><b>10.2.2</b> Representing Words: Word Embeddings</a></li>
<li class="chapter" data-level="10.2.3" data-path="transitioning-to-deep-learning-for-text-analysis.html"><a href="transitioning-to-deep-learning-for-text-analysis.html#handling-sequences-recurrent-neural-networks-rnns"><i class="fa fa-check"></i><b>10.2.3</b> Handling Sequences: Recurrent Neural Networks (RNNs)</a></li>
<li class="chapter" data-level="10.2.4" data-path="transitioning-to-deep-learning-for-text-analysis.html"><a href="transitioning-to-deep-learning-for-text-analysis.html#advanced-architectures-transformers-and-attention"><i class="fa fa-check"></i><b>10.2.4</b> Advanced Architectures: Transformers and Attention</a></li>
<li class="chapter" data-level="10.2.5" data-path="transitioning-to-deep-learning-for-text-analysis.html"><a href="transitioning-to-deep-learning-for-text-analysis.html#evaluating-deep-learning-advantages-and-challenges"><i class="fa fa-check"></i><b>10.2.5</b> Evaluating Deep Learning: Advantages and Challenges</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="practical-exercise-basic-text-classification-with-deep-learning-in-python.html"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html"><i class="fa fa-check"></i><b>10.3</b> Practical Exercise: Basic Text Classification with Deep Learning in Python</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="practical-exercise-basic-text-classification-with-deep-learning-in-python.html"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#setup-importing-libraries"><i class="fa fa-check"></i><b>10.3.1</b> 1. Setup: Importing Libraries</a></li>
<li class="chapter" data-level="10.3.2" data-path="practical-exercise-basic-text-classification-with-deep-learning-in-python.html"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#load-data-imdb-movie-reviews"><i class="fa fa-check"></i><b>10.3.2</b> 2. Load Data: IMDB Movie Reviews</a></li>
<li class="chapter" data-level="10.3.3" data-path="practical-exercise-basic-text-classification-with-deep-learning-in-python.html"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#preprocessing-padding-sequences"><i class="fa fa-check"></i><b>10.3.3</b> 3. Preprocessing: Padding Sequences</a></li>
<li class="chapter" data-level="10.3.4" data-path="practical-exercise-basic-text-classification-with-deep-learning-in-python.html"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#build-the-model"><i class="fa fa-check"></i><b>10.3.4</b> 4. Build the Model</a></li>
<li class="chapter" data-level="10.3.5" data-path="practical-exercise-basic-text-classification-with-deep-learning-in-python.html"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#compile-the-model"><i class="fa fa-check"></i><b>10.3.5</b> 5. Compile the Model</a></li>
<li class="chapter" data-level="10.3.6" data-path="practical-exercise-basic-text-classification-with-deep-learning-in-python.html"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#train-the-model"><i class="fa fa-check"></i><b>10.3.6</b> 6. Train the Model</a></li>
<li class="chapter" data-level="10.3.7" data-path="practical-exercise-basic-text-classification-with-deep-learning-in-python.html"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#evaluate-the-model"><i class="fa fa-check"></i><b>10.3.7</b> 7. Evaluate the Model</a></li>
<li class="chapter" data-level="10.3.8" data-path="practical-exercise-basic-text-classification-with-deep-learning-in-python.html"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#discussion-next-steps"><i class="fa fa-check"></i><b>10.3.8</b> 8. Discussion &amp; Next Steps</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="exercises-and-further-exploration.html"><a href="exercises-and-further-exploration.html"><i class="fa fa-check"></i><b>10.4</b> Exercises and Further Exploration</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="bastiaan.bruinsma@gmail.com" target="blank">Bastiaan Bruinsma</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Quantitative Text Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="practical-exercise-basic-text-classification-with-deep-learning-in-python" class="section level2 hasAnchor" number="10.3">
<h2><span class="header-section-number">10.3</span> Practical Exercise: Basic Text Classification with Deep Learning in Python<a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#practical-exercise-basic-text-classification-with-deep-learning-in-python" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Having discussed the theoretical foundations of deep learning for text, we now transition to a practical application. This exercise will guide you through implementing a simple deep learning model, specifically a feedforward neural network, to classify text sentiment using the Keras API within TensorFlow. While we use a standard dataset of movie reviews for its clarity and pre-labeled nature[cite: 116], the techniques and workflow are directly transferable to a wide array of social science text analysis tasks[cite: 110]. For instance, these methods can be adapted for analyzing sentiment in political tweets or news articles, detecting stances in parliamentary debates or online forum discussions, coding open-ended survey responses, or identifying thematic content in interview transcripts[cite: 111]. Understanding how to numerically represent text and build classifiers is a crucial skill for analyzing large text corpora in social research[cite: 111].</p>
<div id="setup-importing-libraries" class="section level3 hasAnchor" number="10.3.1">
<h3><span class="header-section-number">10.3.1</span> 1. Setup: Importing Libraries<a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#setup-importing-libraries" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Our first step is to import the necessary Python libraries. We will use <code>tensorflow</code> and its high-level API <code>keras</code> for building and training our deep learning model[cite: 112]. <code>numpy</code> will be employed for numerical operations[cite: 113], and <code>pandas</code> could be used for more complex data manipulation, though Keras datasets often load directly in a usable format[cite: 113]. <code>scikit-learn</code> offers tools for tasks like splitting data and evaluating model metrics[cite: 114], although for this specific exercise, Keras functionalities will cover most needs. Optionally, <code>matplotlib</code> can be used for visualizing results, such as training progress[cite: 114].</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb5-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-2"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb5-2" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-3"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb5-3" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb5-4"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb5-4" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb5-5"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb5-5" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.datasets <span class="im">import</span> imdb</span>
<span id="cb5-6"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb5-6" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.preprocessing.sequence <span class="im">import</span> pad_sequences</span>
<span id="cb5-7"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb5-7" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Sequential</span>
<span id="cb5-8"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb5-8" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Embedding, Flatten, Dense</span>
<span id="cb5-9"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb5-9" tabindex="-1"></a><span class="co"># from sklearn.model_selection import train_test_split # Listed in preamble, not used in the script body [cite: 114]</span></span>
<span id="cb5-10"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb5-10" tabindex="-1"></a><span class="co"># Optional: for plotting</span></span>
<span id="cb5-11"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb5-11" tabindex="-1"></a><span class="co"># import matplotlib.pyplot as plt</span></span>
<span id="cb5-12"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb5-12" tabindex="-1"></a></span>
<span id="cb5-13"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb5-13" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;TensorFlow Version:&quot;</span>, tf.__version__)</span></code></pre></div>
</div>
<div id="load-data-imdb-movie-reviews" class="section level3 hasAnchor" number="10.3.2">
<h3><span class="header-section-number">10.3.2</span> 2. Load Data: IMDB Movie Reviews<a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#load-data-imdb-movie-reviews" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For this exercise, we will use the well-known IMDB movie review dataset, which Keras conveniently provides[cite: 116]. This dataset comprises 50,000 movie reviews, each pre-labeled as either positive (represented by 1) or negative (represented by 0)[cite: 116]. When loading the data, we specify <code>num_words=VOCAB_SIZE</code> (e.g., 10,000) to limit our vocabulary to the top <code>VOCAB_SIZE</code> most frequent words in the dataset[cite: 117, 118]. Words that fall outside this selected vocabulary will be treated as “unknown” tokens[cite: 118]. This is a common preprocessing step to manage vocabulary size and focus on more informative words.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb6-1" tabindex="-1"></a><span class="co"># --- Parameters ---</span></span>
<span id="cb6-2"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb6-2" tabindex="-1"></a>VOCAB_SIZE <span class="op">=</span> <span class="dv">10000</span>  <span class="co"># How many unique words to consider [cite: 118]</span></span>
<span id="cb6-3"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb6-3" tabindex="-1"></a><span class="co"># --- End Parameters ---</span></span>
<span id="cb6-4"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb6-5" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Loading IMDB dataset, keeping top </span><span class="sc">{</span>VOCAB_SIZE<span class="sc">}</span><span class="ss"> words...&quot;</span>)</span>
<span id="cb6-6"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb6-6" tabindex="-1"></a>(train_data, train_labels), (test_data, test_labels) <span class="op">=</span> imdb.load_data(num_words<span class="op">=</span>VOCAB_SIZE)</span>
<span id="cb6-7"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb6-7" tabindex="-1"></a></span>
<span id="cb6-8"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb6-8" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;--------------------&quot;</span>)</span>
<span id="cb6-9"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb6-9" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Training entries: </span><span class="sc">{</span><span class="bu">len</span>(train_data)<span class="sc">}</span><span class="ss">, labels: </span><span class="sc">{</span><span class="bu">len</span>(train_labels)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb6-10"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb6-10" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Test entries: </span><span class="sc">{</span><span class="bu">len</span>(test_data)<span class="sc">}</span><span class="ss">, labels: </span><span class="sc">{</span><span class="bu">len</span>(test_labels)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb6-11"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb6-11" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;--------------------&quot;</span>)</span>
<span id="cb6-12"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb6-12" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Example review (sequence of word indices):&quot;</span>)</span>
<span id="cb6-13"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb6-13" tabindex="-1"></a><span class="bu">print</span>(train_data[<span class="dv">0</span>])</span>
<span id="cb6-14"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb6-14" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;--------------------&quot;</span>)</span>
<span id="cb6-15"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb6-15" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Example label (0=Negative, 1=Positive):&quot;</span>)</span>
<span id="cb6-16"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb6-16" tabindex="-1"></a><span class="bu">print</span>(train_labels[<span class="dv">0</span>])</span></code></pre></div>
<p>It is important to understand the format of this data. Each review is already preprocessed into a sequence of integers[cite: 119]. Each integer corresponds to a specific word in a pre-defined dictionary or vocabulary[cite: 119]. For exploration, we can decode these integer sequences back into human-readable words, although this step is not required for model training itself[cite: 120]. The <code>imdb.get_word_index()</code> function provides the word-to-index mapping, to which we add special tokens like <code>&lt;PAD&gt;</code> (for padding), <code>&lt;START&gt;</code> (to mark the beginning), <code>&lt;UNK&gt;</code> (for unknown words), and an unused token[cite: 120].</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-1" tabindex="-1"></a><span class="co"># A dictionary mapping words to an integer index [cite: 120]</span></span>
<span id="cb7-2"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-2" tabindex="-1"></a>word_index <span class="op">=</span> imdb.get_word_index()</span>
<span id="cb7-3"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-4" tabindex="-1"></a><span class="co"># The first indices are reserved; shift original indices by 3 [cite: 120]</span></span>
<span id="cb7-5"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-5" tabindex="-1"></a>word_index <span class="op">=</span> {k:(v<span class="op">+</span><span class="dv">3</span>) <span class="cf">for</span> k,v <span class="kw">in</span> word_index.items()}</span>
<span id="cb7-6"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-6" tabindex="-1"></a>word_index[<span class="st">&quot;&lt;PAD&gt;&quot;</span>] <span class="op">=</span> <span class="dv">0</span>  <span class="co"># Padding token [cite: 120]</span></span>
<span id="cb7-7"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-7" tabindex="-1"></a>word_index[<span class="st">&quot;&lt;START&gt;&quot;</span>] <span class="op">=</span> <span class="dv">1</span> <span class="co"># Start token [cite: 120]</span></span>
<span id="cb7-8"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-8" tabindex="-1"></a>word_index[<span class="st">&quot;&lt;UNK&gt;&quot;</span>] <span class="op">=</span> <span class="dv">2</span>  <span class="co"># Unknown token [cite: 120]</span></span>
<span id="cb7-9"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-9" tabindex="-1"></a>word_index[<span class="st">&quot;&lt;UNUSED&gt;&quot;</span>] <span class="op">=</span> <span class="dv">3</span> <span class="co"># [cite: 120]</span></span>
<span id="cb7-10"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-10" tabindex="-1"></a></span>
<span id="cb7-11"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-11" tabindex="-1"></a>reverse_word_index <span class="op">=</span> <span class="bu">dict</span>([(value, key) <span class="cf">for</span> (key, value) <span class="kw">in</span> word_index.items()])</span>
<span id="cb7-12"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-12" tabindex="-1"></a></span>
<span id="cb7-13"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-13" tabindex="-1"></a><span class="kw">def</span> decode_review(text_indices):</span>
<span id="cb7-14"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-14" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">&#39; &#39;</span>.join([reverse_word_index.get(i, <span class="st">&#39;?&#39;</span>) <span class="cf">for</span> i <span class="kw">in</span> text_indices])</span>
<span id="cb7-15"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-15" tabindex="-1"></a></span>
<span id="cb7-16"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-16" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Decoded first review:&quot;</span>)</span>
<span id="cb7-17"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb7-17" tabindex="-1"></a><span class="bu">print</span>(decode_review(train_data[<span class="dv">0</span>]))</span></code></pre></div>
</div>
<div id="preprocessing-padding-sequences" class="section level3 hasAnchor" number="10.3.3">
<h3><span class="header-section-number">10.3.3</span> 3. Preprocessing: Padding Sequences<a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#preprocessing-padding-sequences" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Neural networks generally require inputs to have a consistent shape and size[cite: 121]. However, our movie reviews naturally vary in length (i.e., they have different numbers of words)[cite: 121]. To address this, we must standardize the length of each review sequence using a technique called <strong>padding</strong>[cite: 121, 122]. We select a <code>MAX_SEQUENCE_LENGTH</code> (e.g., 250 words)[cite: 126]. Reviews shorter than this maximum length will be padded with a special value (0, which we mapped to the <code>&lt;PAD&gt;</code> token) to reach the desired length[cite: 123]. Conversely, reviews longer than <code>MAX_SEQUENCE_LENGTH</code> will be truncated, meaning words beyond this limit will be removed[cite: 124]. We can choose to apply padding and truncation either at the beginning (<code>padding='pre'</code>, <code>truncating='pre'</code>) or at the end (<code>padding='post'</code>, <code>truncating='post'</code>) of the sequences[cite: 125]. While post-padding is used here, pre-padding is often slightly preferred for certain sequence models that we might encounter later in the course[cite: 125].</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-1" tabindex="-1"></a><span class="co"># --- Parameters ---</span></span>
<span id="cb8-2"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-2" tabindex="-1"></a>MAX_SEQUENCE_LENGTH <span class="op">=</span> <span class="dv">250</span>  <span class="co"># Max number of words per review to consider [cite: 126]</span></span>
<span id="cb8-3"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-3" tabindex="-1"></a>PADDING_TYPE <span class="op">=</span> <span class="st">&#39;post&#39;</span>      <span class="co"># Pad/truncate at the &#39;pre&#39; or &#39;post&#39; end [cite: 125, 127]</span></span>
<span id="cb8-4"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-4" tabindex="-1"></a>TRUNCATING_TYPE <span class="op">=</span> <span class="st">&#39;post&#39;</span>   <span class="co"># Truncate from &#39;pre&#39; or &#39;post&#39; [cite: 125, 127]</span></span>
<span id="cb8-5"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-5" tabindex="-1"></a><span class="co"># --- End Parameters ---</span></span>
<span id="cb8-6"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-6" tabindex="-1"></a></span>
<span id="cb8-7"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Padding/Truncating sequences...&quot;</span>)</span>
<span id="cb8-8"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-8" tabindex="-1"></a>train_data_padded <span class="op">=</span> pad_sequences(train_data,</span>
<span id="cb8-9"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-9" tabindex="-1"></a>                                  maxlen<span class="op">=</span>MAX_SEQUENCE_LENGTH,</span>
<span id="cb8-10"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-10" tabindex="-1"></a>                                  padding<span class="op">=</span>PADDING_TYPE,</span>
<span id="cb8-11"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-11" tabindex="-1"></a>                                  truncating<span class="op">=</span>TRUNCATING_TYPE) <span class="co"># [cite: 127]</span></span>
<span id="cb8-12"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-12" tabindex="-1"></a></span>
<span id="cb8-13"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-13" tabindex="-1"></a>test_data_padded <span class="op">=</span> pad_sequences(test_data,</span>
<span id="cb8-14"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-14" tabindex="-1"></a>                                 maxlen<span class="op">=</span>MAX_SEQUENCE_LENGTH,</span>
<span id="cb8-15"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-15" tabindex="-1"></a>                                 padding<span class="op">=</span>PADDING_TYPE,</span>
<span id="cb8-16"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-16" tabindex="-1"></a>                                 truncating<span class="op">=</span>TRUNCATING_TYPE) <span class="co"># [cite: 128]</span></span>
<span id="cb8-17"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-17" tabindex="-1"></a></span>
<span id="cb8-18"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-18" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;--------------------&quot;</span>)</span>
<span id="cb8-19"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-19" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Shape of original train data entry:&quot;</span>, train_data[<span class="dv">0</span>].shape) <span class="co"># Example to show change</span></span>
<span id="cb8-20"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-20" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Shape of padded train data entry:&quot;</span>, train_data_padded[<span class="dv">0</span>].shape)</span>
<span id="cb8-21"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-21" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;--------------------&quot;</span>)</span>
<span id="cb8-22"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-22" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Example Padded Review (scroll right to see potential padding):&quot;</span>)</span>
<span id="cb8-23"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb8-23" tabindex="-1"></a><span class="bu">print</span>(train_data_padded[<span class="dv">0</span>])</span></code></pre></div>
<p>As a good practice, we should also ensure our labels (positive/negative sentiment) are in the correct data type, typically NumPy arrays of type <code>float32</code>, for compatibility with loss functions used during model training[cite: 129].</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb9-1" tabindex="-1"></a>train_labels <span class="op">=</span> np.asarray(train_labels).astype(<span class="st">&#39;float32&#39;</span>) <span class="co"># [cite: 129]</span></span>
<span id="cb9-2"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb9-2" tabindex="-1"></a>test_labels <span class="op">=</span> np.asarray(test_labels).astype(<span class="st">&#39;float32&#39;</span>) <span class="co"># [cite: 129]</span></span>
<span id="cb9-3"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb9-3" tabindex="-1"></a></span>
<span id="cb9-4"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb9-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;--------------------&quot;</span>)</span>
<span id="cb9-5"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb9-5" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Data types check:&quot;</span>)</span>
<span id="cb9-6"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb9-6" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Padded Train Data:&quot;</span>, train_data_padded.dtype)</span>
<span id="cb9-7"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb9-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Train Labels:&quot;</span>, train_labels.dtype)</span></code></pre></div>
</div>
<div id="build-the-model" class="section level3 hasAnchor" number="10.3.4">
<h3><span class="header-section-number">10.3.4</span> 4. Build the Model<a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#build-the-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, we define the architecture of our neural network using the Keras Sequential API, which allows us to build models layer-by-layer[cite: 130]. For this exercise, we will construct a simple feedforward network consisting of an embedding layer, a flatten layer, a hidden dense layer, and an output dense layer[cite: 130].</p>
<ol style="list-style-type: decimal">
<li><p>The <strong>Embedding Layer</strong> is a crucial component for NLP tasks[cite: 131]. It takes the integer-encoded vocabulary (with <code>VOCAB_SIZE</code> unique words) as input[cite: 131]. Its primary function is to learn a dense vector representation, known as an “embedding,” for each word in the vocabulary[cite: 132]. The dimensionality of these learned vectors is specified by <code>EMBEDDING_DIM</code> (e.g., 16)[cite: 133, 143]. The output of this layer for a batch of sequences will have a shape of <code>(batch_size, MAX_SEQUENCE_LENGTH, EMBEDDING_DIM)</code>[cite: 134]. Instead of using sparse representations like one-hot encoding or TF-IDF vectors, embeddings learn meaningful, lower-dimensional representations where words with similar meanings tend to have similar vector representations[cite: 134]. We will explore embeddings in more detail later[cite: 135].</p></li>
<li><p>The <strong>Flatten Layer</strong> follows the embedding layer. Its purpose is to transform the 3D output of the Embedding layer (which is <code>sequence_length * embedding_dim</code> for each review) into a 1D vector[cite: 136]. This flattening is necessary to make the data suitable for input into standard Dense (fully connected) layers[cite: 136]. It’s important to note that this layer discards any sequence information present in the embeddings by collapsing the sequence dimension[cite: 136]. Alternatives like <code>GlobalAveragePooling1D</code> or <code>GlobalMaxPooling1D</code> layers are often better choices as they aggregate information across the sequence dimension, thereby retaining some information regardless of word position, and you might experiment with these later[cite: 137].</p></li>
<li><p>Next is a <strong>Dense Layer</strong>, serving as a hidden layer in our network. This is a standard fully connected layer. We use the ReLU (Rectified Linear Unit) activation function, which is a common choice for hidden layers[cite: 138, 139]. This layer learns higher-level combinations of features from the flattened word embeddings[cite: 139]. The number of neurons in this layer is set by <code>HIDDEN_LAYER_UNITS</code>[cite: 143].</p></li>
<li><p>Finally, the <strong>Output Dense Layer</strong> consists of a single neuron and uses a sigmoid activation function[cite: 140, 141]. The sigmoid function squashes its input into a range between 0 and 1, making it ideal for binary classification tasks like ours[cite: 141]. The output can be interpreted as the probability of the review being positive[cite: 141].</p></li>
</ol>
<p>Connecting this to social science applications, one can conceptualize the Embedding layer as learning the ‘meaning’ of words within the context of the data, and the subsequent Dense layers as learning how combinations of these learned word meanings relate to the outcome variable (e.g., positive or negative sentiment)[cite: 142].</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-1" tabindex="-1"></a><span class="co"># --- Parameters ---</span></span>
<span id="cb10-2"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-2" tabindex="-1"></a>EMBEDDING_DIM <span class="op">=</span> <span class="dv">16</span>       <span class="co"># Dimension of the word vectors learned by Embedding layer [cite: 143]</span></span>
<span id="cb10-3"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-3" tabindex="-1"></a>HIDDEN_LAYER_UNITS <span class="op">=</span> <span class="dv">16</span>  <span class="co"># Number of neurons in the hidden Dense layer [cite: 143]</span></span>
<span id="cb10-4"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-4" tabindex="-1"></a><span class="co"># --- End Parameters ---</span></span>
<span id="cb10-5"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-5" tabindex="-1"></a></span>
<span id="cb10-6"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-6" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Building the model...&quot;</span>)</span>
<span id="cb10-7"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-7" tabindex="-1"></a></span>
<span id="cb10-8"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-8" tabindex="-1"></a>model <span class="op">=</span> Sequential([</span>
<span id="cb10-9"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-9" tabindex="-1"></a>    <span class="co"># 1. Embedding Layer</span></span>
<span id="cb10-10"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-10" tabindex="-1"></a>    Embedding(input_dim<span class="op">=</span>VOCAB_SIZE,           <span class="co"># Size of the vocabulary [cite: 131]</span></span>
<span id="cb10-11"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-11" tabindex="-1"></a>              output_dim<span class="op">=</span>EMBEDDING_DIM,       <span class="co"># Dimension of the embedding vector for each word [cite: 133]</span></span>
<span id="cb10-12"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-12" tabindex="-1"></a>              input_length<span class="op">=</span>MAX_SEQUENCE_LENGTH <span class="co"># Length of input sequences [cite: 144]</span></span>
<span id="cb10-13"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-13" tabindex="-1"></a>             ),</span>
<span id="cb10-14"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-14" tabindex="-1"></a>    <span class="co"># 2. Flatten Layer (or try GlobalAveragePooling1D()) [cite: 136]</span></span>
<span id="cb10-15"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-15" tabindex="-1"></a>    Flatten(),</span>
<span id="cb10-16"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-16" tabindex="-1"></a>    <span class="co"># GlobalAveragePooling1D(), # Alternative to Flatten [cite: 137]</span></span>
<span id="cb10-17"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-17" tabindex="-1"></a></span>
<span id="cb10-18"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-18" tabindex="-1"></a>    <span class="co"># 3. Hidden Dense Layer</span></span>
<span id="cb10-19"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-19" tabindex="-1"></a>    Dense(units<span class="op">=</span>HIDDEN_LAYER_UNITS, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>), <span class="co"># [cite: 138, 139]</span></span>
<span id="cb10-20"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-20" tabindex="-1"></a></span>
<span id="cb10-21"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-21" tabindex="-1"></a>    <span class="co"># 4. Output Dense Layer</span></span>
<span id="cb10-22"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-22" tabindex="-1"></a>    Dense(units<span class="op">=</span><span class="dv">1</span>, activation<span class="op">=</span><span class="st">&#39;sigmoid&#39;</span>) <span class="co"># Sigmoid for binary classification [cite: 140, 141]</span></span>
<span id="cb10-23"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-23" tabindex="-1"></a>])</span>
<span id="cb10-24"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-24" tabindex="-1"></a></span>
<span id="cb10-25"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-25" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;--------------------&quot;</span>)</span>
<span id="cb10-26"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb10-26" tabindex="-1"></a>model.summary() <span class="co"># Print a summary of the model architecture</span></span></code></pre></div>
</div>
<div id="compile-the-model" class="section level3 hasAnchor" number="10.3.5">
<h3><span class="header-section-number">10.3.5</span> 5. Compile the Model<a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#compile-the-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Before we can train our network, we need to configure its learning process using the <code>model.compile()</code> method[cite: 145]. This involves specifying three key components:</p>
<ul>
<li><strong>Optimizer:</strong> This is the algorithm that will be used to update the model’s weights based on the training data and the calculated loss. <code>adam</code> (Adaptive Moment Estimation) is a widely used and generally effective optimizer that often provides good results with default settings[cite: 146]. This relates to the concept of Gradient Descent discussed in the lectures[cite: 146].</li>
<li><strong>Loss Function:</strong> This function measures how inaccurate the model’s predictions are compared to the true labels during training[cite: 147]. For binary (0/1) classification problems where the output layer uses a sigmoid activation function, <code>binary_crossentropy</code> is the standard and appropriate loss function[cite: 148].</li>
<li><strong>Metrics:</strong> These are used to monitor the training and testing steps. While the loss function is used to guide the learning process (weight updates), metrics provide a human-understandable measure of model performance. We will use <code>accuracy</code>, which calculates the proportion of correctly classified reviews[cite: 149].</li>
</ul>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb11-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Compiling the model...&quot;</span>)</span>
<span id="cb11-2"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb11-2" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">&#39;adam&#39;</span>,              <span class="co"># [cite: 146]</span></span>
<span id="cb11-3"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb11-3" tabindex="-1"></a>              loss<span class="op">=</span><span class="st">&#39;binary_crossentropy&#39;</span>,    <span class="co"># [cite: 148]</span></span>
<span id="cb11-4"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb11-4" tabindex="-1"></a>              metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])          <span class="co"># [cite: 149]</span></span>
<span id="cb11-5"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb11-5" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Model compiled.&quot;</span>)</span></code></pre></div>
</div>
<div id="train-the-model" class="section level3 hasAnchor" number="10.3.6">
<h3><span class="header-section-number">10.3.6</span> 6. Train the Model<a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#train-the-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>With the model architecture defined and compiled, we can now train it using the <code>model.fit()</code> method[cite: 151]. This method takes our padded training data (<code>train_data_padded</code>) and corresponding training labels (<code>train_labels</code>) as input[cite: 151].</p>
<p>Several parameters control the training process:
* <code>epochs</code>: This specifies the number of times the model will iterate over the entire training dataset[cite: 152]. One epoch means every sample in the training data has been used once to update the model’s weights.
* <code>batch_size</code>: This defines the number of training samples that are processed before the model’s weights are updated within each epoch[cite: 153]. For example, if the batch size is 512, the model processes 512 reviews, calculates the average loss, and then updates its weights.
* <code>validation_data</code>: This is crucial for monitoring the model’s performance on data it has not been trained on[cite: 154]. We provide our padded test data (<code>test_data_padded</code>) and test labels (<code>test_labels</code>) here. At the end of each epoch, the model evaluates its loss and any specified metrics (like accuracy) on this validation set[cite: 154]. Importantly, the model <em>does not train</em> on this validation data; it is only used for evaluation[cite: 155]. This helps us detect a common issue known as <strong>overfitting</strong>[cite: 155].</p>
<p>Overfitting occurs when the model performs very well on the training data but poorly on unseen data (like the validation set or, later, the test set)[cite: 156]. It essentially means the model has learned the training data “too well,” including its noise and specific quirks, rather than generalizable patterns. Signs of overfitting include the training accuracy continuing to increase while the validation accuracy plateaus or even starts to decrease[cite: 157].</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb12-1" tabindex="-1"></a><span class="co"># --- Parameters ---</span></span>
<span id="cb12-2"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb12-2" tabindex="-1"></a>NUM_EPOCHS <span class="op">=</span> <span class="dv">10</span>    <span class="co"># Number of times to iterate over the entire training dataset [cite: 152, 158]</span></span>
<span id="cb12-3"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb12-3" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">512</span>   <span class="co"># Number of samples processed before weight update [cite: 153, 158]</span></span>
<span id="cb12-4"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb12-4" tabindex="-1"></a><span class="co"># --- End Parameters ---</span></span>
<span id="cb12-5"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb12-5" tabindex="-1"></a></span>
<span id="cb12-6"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb12-6" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Training the model...&quot;</span>)</span>
<span id="cb12-7"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb12-7" tabindex="-1"></a>history <span class="op">=</span> model.fit(train_data_padded,</span>
<span id="cb12-8"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb12-8" tabindex="-1"></a>                    train_labels,                    <span class="co"># [cite: 151]</span></span>
<span id="cb12-9"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb12-9" tabindex="-1"></a>                    epochs<span class="op">=</span>NUM_EPOCHS,               <span class="co"># [cite: 152]</span></span>
<span id="cb12-10"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb12-10" tabindex="-1"></a>                    batch_size<span class="op">=</span>BATCH_SIZE,           <span class="co"># [cite: 153]</span></span>
<span id="cb12-11"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb12-11" tabindex="-1"></a>                    validation_data<span class="op">=</span>(test_data_padded, test_labels), <span class="co"># [cite: 154]</span></span>
<span id="cb12-12"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb12-12" tabindex="-1"></a>                    verbose<span class="op">=</span><span class="dv">1</span> <span class="co"># Set to 1 for progress bar, 2 for less output per epoch, 0 for silent [cite: 159]</span></span>
<span id="cb12-13"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb12-13" tabindex="-1"></a>                   )</span>
<span id="cb12-14"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb12-14" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Model training finished.&quot;</span>)</span></code></pre></div>
<p>Visualizing the training process by plotting the training and validation loss, as well as training and validation accuracy, over epochs is a highly recommended practice[cite: 160]. These plots make it much easier to understand how the training is progressing and to spot overfitting or other training issues[cite: 160].</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-1" tabindex="-1"></a><span class="co"># # Optional: Plotting - uncomment to run [cite: 160]</span></span>
<span id="cb13-2"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-2" tabindex="-1"></a><span class="co"># import matplotlib.pyplot as plt</span></span>
<span id="cb13-3"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-3" tabindex="-1"></a></span>
<span id="cb13-4"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-4" tabindex="-1"></a><span class="co"># history_dict = history.history</span></span>
<span id="cb13-5"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-5" tabindex="-1"></a><span class="co"># acc = history_dict[&#39;accuracy&#39;]</span></span>
<span id="cb13-6"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-6" tabindex="-1"></a><span class="co"># val_acc = history_dict[&#39;val_accuracy&#39;]</span></span>
<span id="cb13-7"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-7" tabindex="-1"></a><span class="co"># loss = history_dict[&#39;loss&#39;]</span></span>
<span id="cb13-8"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-8" tabindex="-1"></a><span class="co"># val_loss = history_dict[&#39;val_loss&#39;]</span></span>
<span id="cb13-9"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-9" tabindex="-1"></a></span>
<span id="cb13-10"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-10" tabindex="-1"></a><span class="co"># epochs_range = range(1, NUM_EPOCHS + 1)</span></span>
<span id="cb13-11"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-11" tabindex="-1"></a></span>
<span id="cb13-12"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-12" tabindex="-1"></a><span class="co"># plt.figure(figsize=(12, 5))</span></span>
<span id="cb13-13"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-13" tabindex="-1"></a></span>
<span id="cb13-14"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-14" tabindex="-1"></a><span class="co"># plt.subplot(1, 2, 1)</span></span>
<span id="cb13-15"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-15" tabindex="-1"></a><span class="co"># plt.plot(epochs_range, loss, &#39;bo&#39;, label=&#39;Training loss&#39;)</span></span>
<span id="cb13-16"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-16" tabindex="-1"></a><span class="co"># plt.plot(epochs_range, val_loss, &#39;b&#39;, label=&#39;Validation loss&#39;)</span></span>
<span id="cb13-17"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-17" tabindex="-1"></a><span class="co"># plt.title(&#39;Training and validation loss&#39;)</span></span>
<span id="cb13-18"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-18" tabindex="-1"></a><span class="co"># plt.xlabel(&#39;Epochs&#39;)</span></span>
<span id="cb13-19"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-19" tabindex="-1"></a><span class="co"># plt.ylabel(&#39;Loss&#39;)</span></span>
<span id="cb13-20"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-20" tabindex="-1"></a><span class="co"># plt.legend()</span></span>
<span id="cb13-21"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-21" tabindex="-1"></a></span>
<span id="cb13-22"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-22" tabindex="-1"></a><span class="co"># plt.subplot(1, 2, 2)</span></span>
<span id="cb13-23"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-23" tabindex="-1"></a><span class="co"># plt.plot(epochs_range, acc, &#39;bo&#39;, label=&#39;Training acc&#39;)</span></span>
<span id="cb13-24"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-24" tabindex="-1"></a><span class="co"># plt.plot(epochs_range, val_acc, &#39;b&#39;, label=&#39;Validation acc&#39;)</span></span>
<span id="cb13-25"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-25" tabindex="-1"></a><span class="co"># plt.title(&#39;Training and validation accuracy&#39;)</span></span>
<span id="cb13-26"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-26" tabindex="-1"></a><span class="co"># plt.xlabel(&#39;Epochs&#39;)</span></span>
<span id="cb13-27"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-27" tabindex="-1"></a><span class="co"># plt.ylabel(&#39;Accuracy&#39;)</span></span>
<span id="cb13-28"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-28" tabindex="-1"></a><span class="co"># plt.legend()</span></span>
<span id="cb13-29"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-29" tabindex="-1"></a></span>
<span id="cb13-30"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-30" tabindex="-1"></a><span class="co"># plt.tight_layout()</span></span>
<span id="cb13-31"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb13-31" tabindex="-1"></a><span class="co"># plt.show()</span></span></code></pre></div>
</div>
<div id="evaluate-the-model" class="section level3 hasAnchor" number="10.3.7">
<h3><span class="header-section-number">10.3.7</span> 7. Evaluate the Model<a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#evaluate-the-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>After training, the final step is to evaluate the model’s performance on the test set (<code>test_data_padded</code> and <code>test_labels</code>). This dataset has been kept separate throughout the training process and provides an unbiased estimate of how well the model is likely to perform on new, unseen data[cite: 161].</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb14-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Evaluating model on test data...&quot;</span>)</span>
<span id="cb14-2"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb14-2" tabindex="-1"></a>loss, accuracy <span class="op">=</span> model.evaluate(test_data_padded, test_labels, verbose<span class="op">=</span><span class="dv">0</span>) <span class="co"># [cite: 161]</span></span>
<span id="cb14-3"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb14-3" tabindex="-1"></a></span>
<span id="cb14-4"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb14-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;--------------------&quot;</span>)</span>
<span id="cb14-5"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb14-5" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Test Loss: </span><span class="sc">{</span>loss<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb14-6"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb14-6" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Test Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb14-7"><a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#cb14-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;--------------------&quot;</span>)</span></code></pre></div>
</div>
<div id="discussion-next-steps" class="section level3 hasAnchor" number="10.3.8">
<h3><span class="header-section-number">10.3.8</span> 8. Discussion &amp; Next Steps<a href="practical-exercise-basic-text-classification-with-deep-learning-in-python.html#discussion-next-steps" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Having completed this exercise, you have successfully trained your first deep learning model for text classification[cite: 162, 163]. This achievement forms a solid foundation for tackling more complex NLP tasks using deep learning.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="transitioning-to-deep-learning-for-text-analysis.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="exercises-and-further-exploration.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["Introduction to Quantitative Text Analysis.pdf", "Introduction to Quantitative Text Analysis.epub"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  },
  "toolbar": {
    "position": "static"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
